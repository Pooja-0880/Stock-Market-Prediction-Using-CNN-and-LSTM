{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dac84ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for working with datasets\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# importing libraries for data visualisation \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "# Importing libraries for web sracping \n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import time \n",
    "import csv\n",
    "\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625f29ce",
   "metadata": {},
   "source": [
    "### import the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7210ca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aapl = pd.read_csv(\"stock_datasets/df_stocktwits_aapl.csv\")\n",
    "df_googl = pd.read_csv(\"stock_datasets/df_stocktwits_googl.csv\")\n",
    "df_ma = pd.read_csv(\"stock_datasets/df_stocktwits_ma.csv\")\n",
    "df_amzn = pd.read_csv(\"stock_datasets/df_stocktwits_amzn.csv\")\n",
    "df_jnj = pd.read_csv(\"stock_datasets/df_stocktwits_jnj.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8809036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_columns(df):\n",
    "    \n",
    "     # remove extra column \n",
    "    df.drop('Unnamed: 0', axis=1, inplace = True)  \n",
    "    \n",
    "\n",
    "df_list = [df_aapl, df_googl,df_ma, df_amzn, df_jnj]\n",
    "\n",
    "for df in df_list: \n",
    "    df= clean_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4de20aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-11-15</td>\n",
       "      <td>RT howardlindzon: Looks like Goldman $gs  is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-11-15</td>\n",
       "      <td>$AAPL http://stks.co/17zl (Weekly Chart) Appro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-11-15</td>\n",
       "      <td>$AAPL down -8.26% this morning? That is a real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-11-15</td>\n",
       "      <td>RT Zguy: $AAPL down -8.26% this morning? That ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-11-15</td>\n",
       "      <td>NEW POST: FROZEN TURKEYS http://stks.co/181s $...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190970</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>Dan Niles: In summary, my 2 overarching invest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190971</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>$AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190972</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>$AAPL $MSFT $GOOGL $AMZN\\nI will buy more and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190973</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>$AAPL bye apple, hello meta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190974</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>$AAPL still don&amp;#39;t have a reason to invest ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190975 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date_time                                              tweet\n",
       "0       2011-11-15  RT howardlindzon: Looks like Goldman $gs  is t...\n",
       "1       2011-11-15  $AAPL http://stks.co/17zl (Weekly Chart) Appro...\n",
       "2       2011-11-15  $AAPL down -8.26% this morning? That is a real...\n",
       "3       2011-11-15  RT Zguy: $AAPL down -8.26% this morning? That ...\n",
       "4       2011-11-15  NEW POST: FROZEN TURKEYS http://stks.co/181s $...\n",
       "...            ...                                                ...\n",
       "190970  2023-01-04  Dan Niles: In summary, my 2 overarching invest...\n",
       "190971  2023-01-04                                              $AAPL\n",
       "190972  2023-01-04  $AAPL $MSFT $GOOGL $AMZN\\nI will buy more and ...\n",
       "190973  2023-01-04                        $AAPL bye apple, hello meta\n",
       "190974  2023-01-04  $AAPL still don&#39;t have a reason to invest ...\n",
       "\n",
       "[190975 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aapl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "164efe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocess_Tweets(data):\n",
    "\t\t\n",
    "\tdata['Text_Cleaned'] = data['tweet'].str.lower()\n",
    "\n",
    "\t## FIX HYPERLINKS\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'https?:\\/\\/.*[\\r\\n]*', ' ',regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'www.*[\\r\\n]*', ' ',regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('https', '', regex=False)\n",
    "\n",
    "\n",
    "\t## FIX INDIVIDUAL SYMBOLS \n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(': ', ' ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(', ', ' ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('. ', ' ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[;\\n~]', ' ', regex=True)\n",
    "\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(\"[]'â€¦*™|]\", '', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[[()!?\"]', '', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('_', '', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('w/', ' with ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('f/', ' for ', regex=False)\n",
    "\n",
    "\n",
    "\t## FIX EMOJIS\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':)', '', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':-)', '', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':(', '', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':-(', '', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('0_o', '', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(';)', '', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('=^.^=', '', regex=False)\n",
    "\n",
    "\n",
    "\t## FIX % SYMBOL\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('%', ' percent ', regex=False)\n",
    "\n",
    "\n",
    "\t## FIX & SYMBOL\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' & ', ' and ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&amp', ' and ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&gt', ' greater than ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('cup&handle', 'cup and handle', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('c&h', 'cup and handle', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('head&shoulders', 'head and shoulders', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('h&s', 'head and shoulders', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('point&figure', 'point and figure', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('p&f', 'point and figure', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('s&p', 'SP500', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('q&a', 'question and answer', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&', ' and ', regex=False)\n",
    "\n",
    "\n",
    "\t## FIX USER TAGS AND HASTAGS\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('@[a-z0-9]+', '', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('#[a-z0-9]+', '', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('@', '', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('#', '', regex=False)\n",
    "\t   \n",
    "\t\t\n",
    "\t## FIX EMBEDDED COMMAS AND PERIODS    \n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z]),([a-z])', r'\\1 \\2', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]),([0-9])', r'\\1\\2', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])[+]+', r'\\1 ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(',', '', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('u.s.', ' us ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('\\.{2,}', ' ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])\\.([a-z])', r'\\1 \\2', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('pdating', 'updating', regex=False) \n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])\\.', r'\\1 ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'\\.([a-z])', r' \\1', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' . ', ' ', regex=False)\n",
    "\t\t\n",
    "\n",
    "\t## FIX + SYMBOL\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'[+]([0-9])', r'positive \\1', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('c+h', 'cup and handle', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('h+s', 'head and shoulders', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('cup+handle', 'cup and handle', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' + ', ' and ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('+ ', ' ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])[+]([a-z])', r'\\1 and \\2', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('+', '', regex=False)\n",
    "\n",
    "\n",
    "\n",
    "\t\t\n",
    "\t## FIX - SYMBOL\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])[-]+([a-z])', r'\\1 \\2', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z]) - ([a-z])', r'\\1 to \\2', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]) -([0-9\\.])', r'\\1 to \\2', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r' [-]([0-9])', r' negative \\1', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])-([0-9\\.])', r'\\1 to \\2', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]) - ([0-9\\.])', r'\\1 to \\2', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9a-z])-([0-9a-z])', r'\\1 \\2', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[-]+[>]', ' ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [-]+ ', ' ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('-', ' ', regex=False)\n",
    "\n",
    "\n",
    "\n",
    "\t## FIX $ SYMBOL\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[$][0-9\\.]', ' dollars ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('$', '', regex=False)\n",
    "\n",
    "\n",
    "\t## FIX = SYMBOL\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('=', ' equals ', regex=False)\n",
    "\n",
    "\t\t\n",
    "\t## FIX / SYMBOL\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('b/c', ' because ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('b/out', ' break out ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('b/o', ' break out ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('p/e', ' pe ratio ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [/]+ ', ' ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/2 ', ' .5 ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/4 ', ' .25 ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 3/4 ', ' .75 ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/3 ', ' .3 ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 2/3 ', ' .6 ', regex=False)\n",
    "\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[/]{2,}', ' ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])/([a-z])', r'\\1 and \\2', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+/[0-9]+/[0-9]+', '', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]{3,})/([0-9\\.]{2,})', r'\\1 to \\2', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]{2,})/([0-9\\.]{3,})', r'\\1 to \\2', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[a-z0-9]+/[a-z0-9]+', ' ', regex=True)\n",
    "\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('/', '', regex=False)\n",
    "\n",
    "\n",
    "\t## FIX < > SYMBOLS\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[<]+ ', ' ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('<', ' less than ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [>]+', ' ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('>', ' greater than ', regex=False)\n",
    "\n",
    "\n",
    "\t## FIX : SYMBOL\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+:[0-9]+am', ' ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+:[0-9]', ' ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':', ' ', regex=False)\n",
    "\n",
    "\n",
    "\t## FIX UNITS\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('user ', ' ', regex=False)\n",
    "\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)dma', r'\\1 displaced moving average ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'dma([0-9]+)', r'\\1 displaced moving average ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)sma', r'\\1 simple moving average ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'sma([0-9]+)', r'\\1 simple moving average ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)ema', r'\\1 expontential moving average ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'ema([0-9]+)', r'\\1 expontential moving average ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)ma', r'\\1 moving average ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'ma([0-9]+)', r'\\1 moving average ', regex=True)\n",
    "\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mos', r'\\1 months ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])minute', r'\\1 minute ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])minutes', r'\\1 minutes ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])min', r'\\1 minute ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mins', r'\\1 minutes ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])day', r'\\1 day ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])days', r'\\1 days ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])wk', r'\\1 week ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' wk ', ' week ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' wknd ', ' weekend ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])wks', r'\\1 weeks ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])hours', r'\\1 hours ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])hour', r'\\1 hour ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])yr', r'\\1 year ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])yrs', r'\\1 years ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' yr', ' year ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])am', r'\\1 am ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])pm', r'\\1 pm ', regex=True)\n",
    "\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])est', r'\\1 ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])ish', r'\\1 ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9 ])pts', r'\\1 points ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])x', r'\\1 times ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])th', r'\\1 ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])rd', r'\\1 ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])st', r'\\1 ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])nd', r'\\1 ', regex=True)\n",
    "\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('mrkt', 'market', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' vol ', ' volume ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' ptrend', ' positive trend ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' ppl', ' people ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' pts', ' points ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' pt', ' point ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' l(ol){1,}', ' laugh ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('imho', ' in my opinion ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('prev ', 'previous ', regex=True)\n",
    "\n",
    "\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1q', ' first quarter ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 2q', ' second quarter ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 3q', ' third quarter ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 4q', ' fourth quarter ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q1', ' first quarter ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q2', ' second quarter ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q3', ' third quarter ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q4', ' fourth quarter ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 10q ', ' form 10 ', regex=False)\n",
    "\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])million', r'\\1 million ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mil', r'\\1 million ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' mil ', ' million ', regex=False)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])billion', r'\\1 billion ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])cents', r'\\1 cents ', regex=True)\n",
    "\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])3d', r'\\1 3 dimensional ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])gb', r'\\1 3 gigabytes ', regex=True)\n",
    "\n",
    "\n",
    "\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])c', r'\\1 calls ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])y', r'\\1 year ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])p', r'\\1 puts ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])d', r'\\1 days ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])h', r'\\1 hour ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])s', r'\\1 ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])k1', r'\\1 thousand ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])k', r'\\1 thousand ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])m', r'\\1 million ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])b', r'\\1 billion ', regex=True)\n",
    "\n",
    "\t\t\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])([a-z])', r'\\1 \\2', regex=True)\n",
    "\n",
    "\t## FIX EXTRA SPACES AND ENDING PUNCTUATION\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' +', ' ', regex=True)\n",
    "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.strip(' .!?,)(:-')\n",
    "\n",
    "\n",
    "\treturn data\n",
    "\n",
    "\n",
    "\n",
    "df_list = [df_aapl, df_googl,df_ma, df_amzn, df_jnj]\n",
    "\n",
    "for df in df_list: \n",
    "    df= Preprocess_Tweets(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2672ed27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbe817c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aapl.to_csv(\"stock_datasets/df_AAPL.csv\")\n",
    "df_googl.to_csv(\"stock_datasets/df_GOOGL.csv\")\n",
    "df_ma.to_csv(\"stock_datasets/df_MA.csv\")\n",
    "df_amzn.to_csv(\"stock_datasets/df_AMZN.csv\")\n",
    "df_jnj.to_csv(\"stock_datasets/df_JNJ.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f7b053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbb776f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84c48cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
